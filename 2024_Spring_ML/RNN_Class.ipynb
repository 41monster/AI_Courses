{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41monster/AI_Courses/blob/main/2024_Spring_ML/RNN_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Of Recurrent Neural Networks\n",
        "\n",
        "**Created By**: Sangam Khanal"
      ],
      "metadata": {
        "id": "YFgNOJfUVq9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recurrent Neural Networks From Scratch\n",
        "\n",
        "The equation of RNNs is:\n",
        "$$\n",
        "h_t = tanh(x_tW_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})\n",
        "$$\n"
      ],
      "metadata": {
        "id": "F3PCujmtV7sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "torch.manual_seed(0)\n",
        "class CustomRNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.Wx = nn.Parameter(torch.randn(input_size, output_size))\n",
        "        self.Wh = nn.Parameter(torch.randn(output_size, output_size))\n",
        "        self.b = nn.Parameter(torch.zeros(1, output_size))\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        outputs = []\n",
        "        for x in inputs:\n",
        "            hidden = torch.tanh((x@self.Wx) +(hidden@self.Wh) + self.b)\n",
        "            outputs.append(hidden)\n",
        "        return outputs, hidden\n",
        "\n",
        "input = torch.rand(11,1,59)\n",
        "hidden = torch.rand(1,1,30)\n",
        "my_rnn = CustomRNN(59, 30)\n",
        "out = my_rnn(input, hidden)\n",
        "print(out[1], out[0][-1])"
      ],
      "metadata": {
        "id": "lFwh-G6uWIu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7164789b-26b9-454b-ff1a-eb1ac41940cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.9966, -0.6313, -0.9843, -0.9996,  1.0000,  0.9993,  0.9812,\n",
            "          -0.9825,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  0.9998,\n",
            "          -0.9989,  0.9992, -0.3938,  1.0000, -0.8379, -0.9995,  1.0000,\n",
            "           0.9998,  0.6627, -1.0000, -1.0000,  1.0000,  0.9853, -0.9997,\n",
            "          -0.9978, -1.0000]]], grad_fn=<TanhBackward0>) tensor([[[-0.9966, -0.6313, -0.9843, -0.9996,  1.0000,  0.9993,  0.9812,\n",
            "          -0.9825,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  0.9998,\n",
            "          -0.9989,  0.9992, -0.3938,  1.0000, -0.8379, -0.9995,  1.0000,\n",
            "           0.9998,  0.6627, -1.0000, -1.0000,  1.0000,  0.9853, -0.9997,\n",
            "          -0.9978, -1.0000]]], grad_fn=<TanhBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM\n",
        "\n",
        "The LSTM equations are\n",
        "$$\n",
        "i_t = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi}) \\\\\n",
        "f_t = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf}) \\\\\n",
        "g_t = tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{ho}) \\\\\n",
        "o_t = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho}) \\\\\n",
        "c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
        "h_t = o_t \\odot tanh(c_t)\n",
        "$$"
      ],
      "metadata": {
        "id": "wpHAXju3WJh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.x2h = nn.Linear(input_size, 4*hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, 4*hidden_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.init_param()\n",
        "\n",
        "    def init_param(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for p in self.parameters():\n",
        "            p.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, input, states):\n",
        "        h_t, c_t = states\n",
        "        gates = self.x2h(input) + self.h2h(h_t)\n",
        "        it, ft, gt, ot = torch.split(gates, self.hidden_size, dim = -1)\n",
        "        it = torch.sigmoid(it)\n",
        "        ft = torch.sigmoid(ft)\n",
        "        gt = self.tanh(gt)\n",
        "        ot = torch.sigmoid(ot)\n",
        "        ct = ft*c_t + it * gt\n",
        "        ht = ot * self.tanh(ct)\n",
        "        return ht, ct\n",
        "\n",
        "lstm_cell = LSTMCell(10,20)\n",
        "inp = torch.rand(5,4,10)\n",
        "ht = torch.rand(5,4,20)\n",
        "ct = torch.rand(5,4,20)\n",
        "h, c = lstm_cell(inp, (ht,ct))\n",
        "print(h.shape, c.shape)"
      ],
      "metadata": {
        "id": "Kwendx_uVyNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2456ba50-6c7e-4835-8f4c-bc5191f05b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 4, 20]) torch.Size([5, 4, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you add the bias in the LSTM Network?"
      ],
      "metadata": {
        "id": "kWq61a9yJDvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's use our neural networks"
      ],
      "metadata": {
        "id": "L1vrEoaoMjgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://download.pytorch.org/tutorial/data.zip; unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbC2_cO4Mlx7",
        "outputId": "3aece164-7080-4524-826d-382db1318233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2814k  100 2814k    0     0  5277k      0 --:--:-- --:--:-- --:--:-- 5280k\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOEpyIPXf4t0",
        "outputId": "73b89145-7775-4dae-8755-ae5a8793dda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "V23ZNFo4fkOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from string import ascii_letters\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from unidecode import unidecode\n",
        "\n",
        "_ = torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "3mYHZjkuMn2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/names\"\n",
        "\n",
        "lang2label = {\n",
        "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long)\n",
        "    for i, file_name in enumerate(os.listdir(data_dir))\n",
        "}\n",
        "print(lang2label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g6-EvBRgA-D",
        "outputId": "20a0987f-2bd8-4070-c9c5-2127075f6f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Portuguese': tensor([0]), 'Czech': tensor([1]), 'English': tensor([2]), 'German': tensor([3]), 'Italian': tensor([4]), 'Dutch': tensor([5]), 'Greek': tensor([6]), 'Spanish': tensor([7]), 'Chinese': tensor([8]), 'Irish': tensor([9]), 'Korean': tensor([10]), 'French': tensor([11]), 'Arabic': tensor([12]), 'Scottish': tensor([13]), 'Polish': tensor([14]), 'Russian': tensor([15]), 'Japanese': tensor([16]), 'Vietnamese': tensor([17])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {letter: i for i, letter in enumerate(ascii_letters + \" .,:;-'\")}\n",
        "num_letters = len(char2idx)\n",
        "\n",
        "def name2tensor(name):\n",
        "    tensor = torch.zeros(len(name), num_letters)\n",
        "    for i, char in enumerate(name):\n",
        "        tensor[i][char2idx[char]] = 1\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "jGY5_BUAgGDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name2tensor(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCC-GCHggQuK",
        "outputId": "e6fb7cf3-b617-4b13-e583-212038697a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_names = []\n",
        "target_langs = []\n",
        "\n",
        "for file in os.listdir(data_dir):\n",
        "    with open(os.path.join(data_dir, file)) as f:\n",
        "        lang = file.split(\".\")[0]\n",
        "        names = [unidecode(line.rstrip()) for line in f]\n",
        "        for name in names:\n",
        "            try:\n",
        "                tensor_names.append(name2tensor(name))\n",
        "                target_langs.append(lang2label[lang])\n",
        "            except KeyError:\n",
        "                pass"
      ],
      "metadata": {
        "id": "Cw93ucJ2gTxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    range(len(target_langs)),\n",
        "    test_size=0.1,\n",
        "    shuffle=True,\n",
        "    stratify=target_langs\n",
        ")\n",
        "\n",
        "train_dataset = [\n",
        "    (tensor_names[i], target_langs[i])\n",
        "    for i in train_idx\n",
        "]\n",
        "\n",
        "test_dataset = [\n",
        "    (tensor_names[i], target_langs[i])\n",
        "    for i in test_idx\n",
        "]"
      ],
      "metadata": {
        "id": "jW1nzWEJgZbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for curr_x, _ in train_dataset:\n",
        "    print(curr_x.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2_3cI1vELcK",
        "outputId": "f0f73fc1-c8ea-49a9-8f8c-751960bbaa21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train: {len(train_dataset)}\")\n",
        "print(f\"Test: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5QD9LXngaW6",
        "outputId": "719105d1-387c-46dd-b34e-3417631c9d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 18063\n",
            "Test: 2007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the architecture"
      ],
      "metadata": {
        "id": "v-YbAvm1-0uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class RNNNetwork(nn.Module):\n",
        "    def __init__(self, num_letters):\n",
        "        super().__init__()\n",
        "        self.rnn = torch.nn.RNN(num_letters, 100, 1, batch_first = True)\n",
        "        self.linear = torch.nn.Linear(100,18)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, hidden = self.rnn(x)\n",
        "        hd = self.linear(hidden[0])\n",
        "        return hd\n",
        "        # return F.softmax(hd, dim = -1)"
      ],
      "metadata": {
        "id": "mJEbW1sq-7Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myRNN = RNNNetwork(num_letters)\n",
        "myRNN(curr_x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ8Bf4NL_2tJ",
        "outputId": "22ae002c-63b7-486a-9257-4e4827a71868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNNetwork(num_letters)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "x7s18qsvAIzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "print_interval = 3000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    random.shuffle(train_dataset)\n",
        "    for i, (name, label) in enumerate(train_dataset):\n",
        "        name = torch.unsqueeze(name, axis = 0)\n",
        "        output= model(name)\n",
        "        loss = criterion(output, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % print_interval == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
        "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
        "                f\"Loss: {loss.item():.4f}\"\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80YaiKj7AI1y",
        "outputId": "cd47ed01-6ac1-46c7-baca-3bf0c525c026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [3000/18063], Loss: 3.3134\n",
            "Epoch [1/1], Step [6000/18063], Loss: 0.6150\n",
            "Epoch [1/1], Step [9000/18063], Loss: 0.0048\n",
            "Epoch [1/1], Step [12000/18063], Loss: 0.2323\n",
            "Epoch [1/1], Step [15000/18063], Loss: 4.1626\n",
            "Epoch [1/1], Step [18000/18063], Loss: 0.9784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FDrDVdn7KCgX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}